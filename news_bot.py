import requests
import feedparser
import json
import re
from datetime import datetime
from config import (
    NEWS_RSS_FEEDS as RSS_FEEDS,
    NEWS_AI_KEYWORDS as AI_KEYWORDS,
    NEWS_QUANTUM_KEYWORDS as QUANTUM_KEYWORDS,
    send_telegram_message
)

def check_keywords_in_text(text, keywords):
    """í…ìŠ¤íŠ¸ì— í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸"""
    if not text:
        return False
    text_lower = text.lower()
    for keyword in keywords:
        if keyword.lower() in text_lower:
            return True
    return False

def extract_key_sentences(text, keywords):
    """í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë¬¸ì¥ ìš°ì„  ì¶”ì¶œ"""
    if not text:
        return ""
    
    sentences = text.replace('!', '.').replace('?', '.').split('.')
    sentences = [s.strip() for s in sentences if len(s.strip()) > 10]
    
    # í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë¬¸ì¥ ì°¾ê¸°
    keyword_sentences = []
    for sentence in sentences:
        for keyword in keywords:
            if keyword.lower() in sentence.lower():
                keyword_sentences.append(sentence)
                break
    
    # í‚¤ì›Œë“œ ë¬¸ì¥ì´ ìˆìœ¼ë©´ ìš°ì„ , ì—†ìœ¼ë©´ ì²« ë¬¸ì¥
    if keyword_sentences:
        return keyword_sentences[0] + "."
    elif sentences:
        return sentences[0] + "."
    
    return text[:100] + "..." if len(text) > 100 else text

def clean_and_enhance_summary(news_item, relevant_keywords):
    """RSS ìš”ì•½ì„ ì •ë¦¬í•˜ê³  ê°œì„ """
    title = news_item.get('title', '')
    summary = news_item.get('summary', '')
    
    # HTML íƒœê·¸ ì œê±°
    summary = re.sub(r'<[^>]+>', '', summary)
    summary = summary.replace('&nbsp;', ' ').replace('&amp;', '&')
    
    # ìš”ì•½ì´ ìˆìœ¼ë©´ ìŠ¤ë§ˆíŠ¸í•˜ê²Œ ì²˜ë¦¬
    if summary and len(summary) > 20:
        # ì œëª©ê³¼ ì¤‘ë³µë˜ëŠ” ë‚´ìš© ì œê±°
        if title.lower() in summary.lower():
            summary = summary.replace(title, '').strip()
        
        # í‚¤ì›Œë“œ ê¸°ë°˜ í•µì‹¬ ë¬¸ì¥ ì¶”ì¶œ
        enhanced = extract_key_sentences(summary, relevant_keywords)
        return enhanced
    
    # ìš”ì•½ì´ ì—†ìœ¼ë©´ ì œëª©ì—ì„œ í‚¤ì›Œë“œ ì¤‘ì‹¬ìœ¼ë¡œ ì„¤ëª…
    return f"'{', '.join(relevant_keywords[:2])}' ê´€ë ¨ ë‰´ìŠ¤"

def filter_news_by_keywords(entries, keywords, category_name):
    """í‚¤ì›Œë“œë¡œ ë‰´ìŠ¤ í•„í„°ë§ (í–¥ìƒëœ ë²„ì „)"""
    filtered_news = []
    
    for entry in entries:
        title = entry.title if hasattr(entry, 'title') else ""
        summary = entry.summary if hasattr(entry, 'summary') else ""
        full_text = f"{title} {summary}"
        
        # í‚¤ì›Œë“œ ë§¤ì¹­ í™•ì¸
        matched_keywords = []
        for keyword in keywords:
            if keyword.lower() in full_text.lower():
                matched_keywords.append(keyword)
        
        if matched_keywords:
            # í–¥ìƒëœ ìš”ì•½ ìƒì„±
            enhanced_summary = clean_and_enhance_summary(
                {'title': title, 'summary': summary}, 
                matched_keywords
            )
            
            filtered_news.append({
                'title': title,
                'link': entry.link if hasattr(entry, 'link') else "",
                'published': entry.published if hasattr(entry, 'published') else 'Unknown',
                'summary': summary,
                'enhanced_summary': enhanced_summary,  # ìƒˆë¡œìš´ í•„ë“œ
                'matched_keywords': matched_keywords,
                'category': category_name,
                'source': '',
                'importance_score': len(matched_keywords)  # í‚¤ì›Œë“œ ê°œìˆ˜ë¡œ ì¤‘ìš”ë„ ì ìˆ˜
            })
    
    # ì¤‘ìš”ë„ ìˆœìœ¼ë¡œ ì •ë ¬ (í‚¤ì›Œë“œê°€ ë§ì´ ë§¤ì¹­ëœ ë‰´ìŠ¤ ìš°ì„ )
    filtered_news.sort(key=lambda x: x['importance_score'], reverse=True)
    return filtered_news

def smart_truncate(text, length):
    """ìŠ¤ë§ˆíŠ¸í•˜ê²Œ í…ìŠ¤íŠ¸ ìë¥´ê¸° (ë‹¨ì–´ ë‹¨ìœ„)"""
    if len(text) <= length:
        return text
    
    # ê¸¸ì´ ë‚´ì—ì„œ ë§ˆì§€ë§‰ ê³µë°± ì°¾ê¸°
    truncated = text[:length]
    last_space = truncated.rfind(' ')
    
    if last_space > length * 0.8:  # 80% ì´ìƒì´ë©´ ë‹¨ì–´ ë‹¨ìœ„ë¡œ ìë¥´ê¸°
        return truncated[:last_space] + "..."
    else:
        return truncated + "..."

def collect_filtered_news():
    """ëª¨ë“  ì‚¬ì´íŠ¸ì—ì„œ ë‰´ìŠ¤ ìˆ˜ì§‘ ë° í•„í„°ë§"""
    all_filtered_news = []
    
    print("ğŸ” ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘...")
    
    for site_name, feed_url in RSS_FEEDS.items():
        print(f"ğŸ“° {site_name} ë¶„ì„ ì¤‘...")
        try:
            # RSS í”¼ë“œ íŒŒì‹±
            feed = feedparser.parse(feed_url)
            
            if not hasattr(feed, 'entries') or not feed.entries:
                print(f"   âš ï¸ {site_name}: ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
                continue
            
            # AI í‚¤ì›Œë“œë¡œ í•„í„°ë§
            ai_news = filter_news_by_keywords(feed.entries, AI_KEYWORDS, "AI")
            for news in ai_news:
                news['source'] = site_name
            
            # ì–‘ì í‚¤ì›Œë“œë¡œ í•„í„°ë§  
            quantum_news = filter_news_by_keywords(feed.entries, QUANTUM_KEYWORDS, "Quantum")
            for news in quantum_news:
                news['source'] = site_name
            
            print(f"   ğŸ¤– AI ê´€ë ¨: {len(ai_news)}ê°œ")
            print(f"   âš›ï¸ ì–‘ì ê´€ë ¨: {len(quantum_news)}ê°œ")
            
            all_filtered_news.extend(ai_news)
            all_filtered_news.extend(quantum_news)
            
        except Exception as e:
            print(f"   âŒ {site_name} ì˜¤ë¥˜: {e}")
            continue
    
    return all_filtered_news

def create_news_summary(news_list, max_news=8):
    """ë‰´ìŠ¤ ìš”ì•½ ë©”ì‹œì§€ ìƒì„± (í–¥ìƒëœ ë¬´ë£Œ ë²„ì „)"""
    if not news_list:
        return "ğŸ“° ì˜¤ëŠ˜ì€ AI/ì–‘ì ê´€ë ¨ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    # ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë¶„ë¥˜ (ì´ë¯¸ ì¤‘ìš”ë„ìˆœ ì •ë ¬ë¨)
    ai_news = [n for n in news_list if n['category'] == 'AI']
    quantum_news = [n for n in news_list if n['category'] == 'Quantum']
    
    # ë©”ì‹œì§€ êµ¬ì„±
    current_time = datetime.now().strftime('%Y-%m-%d %H:%M')
    message = f"ğŸ¤– <b>AI & ì–‘ì ë‰´ìŠ¤ ìš”ì•½</b>\n"
    message += f"ğŸ“… {current_time} (í•œêµ­ì‹œê°„)\n"
    message += f"ğŸ¯ ì´ {len(news_list)}ê°œ ë‰´ìŠ¤ ì¤‘ ì£¼ìš” ë‰´ìŠ¤\n\n"
    
    if ai_news:
        message += f"ğŸ¤– <b>AI ë‰´ìŠ¤ TOP {min(len(ai_news), max_news//2)}</b>\n\n"
        for i, news in enumerate(ai_news[:max_news//2], 1):
            title = smart_truncate(news['title'], 85)
            
            message += f"<b>{i}. {title}</b>\n"
            message += f"   ğŸ“° {news['source']}\n"
            
            # í–¥ìƒëœ ìš”ì•½ ì‚¬ìš©
            enhanced_summary = news.get('enhanced_summary', '')
            if enhanced_summary and len(enhanced_summary) > 5:
                message += f"   ğŸ’¡ {enhanced_summary}\n"
            
            # ë§¤ì¹­ëœ í‚¤ì›Œë“œ í‘œì‹œ (ìµœëŒ€ 3ê°œ)
            if news.get('matched_keywords'):
                keywords = news['matched_keywords'][:3]
                message += f"   ğŸ·ï¸ {', '.join(keywords)}\n"
            
            message += f"   ğŸ”— <a href='{news['link']}'>ê¸°ì‚¬ ë³´ê¸°</a>\n\n"
    
    if quantum_news:
        message += f"âš›ï¸ <b>ì–‘ì ë‰´ìŠ¤ TOP {min(len(quantum_news), max_news//2)}</b>\n\n"
        for i, news in enumerate(quantum_news[:max_news//2], 1):
            title = smart_truncate(news['title'], 85)
            
            message += f"<b>{i}. {title}</b>\n"
            message += f"   ğŸ“° {news['source']}\n"
            
            enhanced_summary = news.get('enhanced_summary', '')
            if enhanced_summary and len(enhanced_summary) > 5:
                message += f"   ğŸ’¡ {enhanced_summary}\n"
            
            if news.get('matched_keywords'):
                keywords = news['matched_keywords'][:3]
                message += f"   ğŸ·ï¸ {', '.join(keywords)}\n"
            
            message += f"   ğŸ”— <a href='{news['link']}'>ê¸°ì‚¬ ë³´ê¸°</a>\n\n"
    
    # í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ ê¸¸ì´ ì œí•œ (4096ì)
    if len(message) > 3800:
        message = message[:3800] + "...\n\nğŸ“± <i>ë” ë§ì€ ë‰´ìŠ¤ê°€ ìˆìŠµë‹ˆë‹¤!</i>"
    
    # í†µê³„ ì •ë³´ ì¶”ê°€
    total_ai = len(ai_news)
    total_quantum = len(quantum_news)
    message += f"\nğŸ“Š ì˜¤ëŠ˜ì˜ ë‰´ìŠ¤ í†µê³„\n"
    message += f"   ğŸ¤– AI: {total_ai}ê°œ | âš›ï¸ ì–‘ì: {total_quantum}ê°œ\n"
    message += f"\nğŸ”„ <i>ë‹¤ìŒ ì—…ë°ì´íŠ¸: 12ì‹œê°„ í›„</i>\n"
    message += f"ğŸ¤– <i>ìŠ¤ë§ˆíŠ¸ ë‰´ìŠ¤ë´‡ v2.0</i>"
    
    return message

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ ë‰´ìŠ¤ë´‡ ì‹œì‘!")
    print(f"â° ì‹¤í–‰ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    try:
        # 1. ë‰´ìŠ¤ ìˆ˜ì§‘
        news_list = collect_filtered_news()
        print(f"ğŸ“Š ì´ ìˆ˜ì§‘ëœ ë‰´ìŠ¤: {len(news_list)}ê°œ")
        
        # 2. ìš”ì•½ ìƒì„±
        summary = create_news_summary(news_list, max_news=8)
        
        # 3. í…”ë ˆê·¸ë¨ ì „ì†¡
        success = send_telegram_message(summary)
        
        if success:
            print("âœ… ë‰´ìŠ¤ ìš”ì•½ ì „ì†¡ ì™„ë£Œ!")
        else:
            print("âŒ ì „ì†¡ ì‹¤íŒ¨")
            
    except Exception as e:
        error_msg = f"âŒ ë‰´ìŠ¤ë´‡ ì‹¤í–‰ ì˜¤ë¥˜: {e}"
        print(error_msg)
        
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê´€ë¦¬ìì—ê²Œ ì•Œë¦¼
        send_telegram_message(f"ğŸš¨ <b>ë‰´ìŠ¤ë´‡ ì˜¤ë¥˜ ë°œìƒ</b>\n\n{error_msg}")

if __name__ == "__main__":
    main()
