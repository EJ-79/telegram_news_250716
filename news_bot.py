import requests
import feedparser
import json
import re
from datetime import datetime
from config import (
    NEWS_RSS_FEEDS as RSS_FEEDS,
    NEWS_AI_KEYWORDS as AI_KEYWORDS,
    NEWS_QUANTUM_KEYWORDS as QUANTUM_KEYWORDS,
    send_telegram_message
)

def check_keywords_in_text(text, keywords):
    """í…ìŠ¤íŠ¸ì— í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸"""
    if not text:
        return False
    text_lower = text.lower()
    for keyword in keywords:
        if keyword.lower() in text_lower:
            return True
    return False

def extract_key_sentences(text, keywords):
    """í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë¬¸ì¥ ìš°ì„  ì¶”ì¶œ"""
    if not text:
        return ""
    
    sentences = text.replace('!', '.').replace('?', '.').split('.')
    sentences = [s.strip() for s in sentences if len(s.strip()) > 10]
    
    # í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë¬¸ì¥ ì°¾ê¸°
    keyword_sentences = []
    for sentence in sentences:
        for keyword in keywords:
            if keyword.lower() in sentence.lower():
                keyword_sentences.append(sentence)
                break
    
    # í‚¤ì›Œë“œ ë¬¸ì¥ì´ ìˆìœ¼ë©´ ìš°ì„ , ì—†ìœ¼ë©´ ì²« ë¬¸ì¥
    if keyword_sentences:
        return keyword_sentences[0] + "."
    elif sentences:
        return sentences[0] + "."
    
    return text[:100] + "..." if len(text) > 100 else text

def clean_and_enhance_summary(news_item, relevant_keywords):
    """RSS ìš”ì•½ì„ ì •ë¦¬í•˜ê³  ê°œì„ """
    title = news_item.get('title', '')
    summary = news_item.get('summary', '')
    
    # HTML íƒœê·¸ ì œê±°
    summary = re.sub(r'<[^>]+>', '', summary)
    summary = summary.replace('&nbsp;', ' ').replace('&amp;', '&')
    
    # ìš”ì•½ì´ ìˆìœ¼ë©´ ìŠ¤ë§ˆíŠ¸í•˜ê²Œ ì²˜ë¦¬
    if summary and len(summary) > 20:
        # ì œëª©ê³¼ ì¤‘ë³µë˜ëŠ” ë‚´ìš© ì œê±°
        if title.lower() in summary.lower():
            summary = summary.replace(title, '').strip()
        
        # í‚¤ì›Œë“œ ê¸°ë°˜ í•µì‹¬ ë¬¸ì¥ ì¶”ì¶œ
        enhanced = extract_key_sentences(summary, relevant_keywords)
        return enhanced
    
    # ìš”ì•½ì´ ì—†ìœ¼ë©´ ì œëª©ì—ì„œ í‚¤ì›Œë“œ ì¤‘ì‹¬ìœ¼ë¡œ ì„¤ëª…
    return f"'{', '.join(relevant_keywords[:2])}' ê´€ë ¨ ë‰´ìŠ¤"

def filter_news_by_keywords(entries, keywords, category_name):
    """í‚¤ì›Œë“œë¡œ ë‰´ìŠ¤ í•„í„°ë§ (í–¥ìƒëœ ë²„ì „)"""
    filtered_news = []
    
    for entry in entries:
        title = entry.title if hasattr(entry, 'title') else ""
        summary = entry.summary if hasattr(entry, 'summary') else ""
        full_text = f"{title} {summary}"
        
        # í‚¤ì›Œë“œ ë§¤ì¹­ í™•ì¸
        matched_keywords = []
        for keyword in keywords:
            if keyword.lower() in full_text.lower():
                matched_keywords.append(keyword)
        
        if matched_keywords:
            # í–¥ìƒëœ ìš”ì•½ ìƒì„±
            enhanced_summary = clean_and_enhance_summary(
                {'title': title, 'summary': summary}, 
                matched_keywords
            )
            
            filtered_news.append({
                'title': title,
                'link': entry.link if hasattr(entry, 'link') else "",
                'published': entry.published if hasattr(entry, 'published') else 'Unknown',
                'summary': summary,
                'enhanced_summary': enhanced_summary,  # ìƒˆë¡œìš´ í•„ë“œ
                'matched_keywords': matched_keywords,
                'category': category_name,
                'source': '',
                'importance_score': len(matched_keywords)  # í‚¤ì›Œë“œ ê°œìˆ˜ë¡œ ì¤‘ìš”ë„ ì ìˆ˜
            })
    
    # ì¤‘ìš”ë„ ìˆœìœ¼ë¡œ ì •ë ¬ (í‚¤ì›Œë“œê°€ ë§ì´ ë§¤ì¹­ëœ ë‰´ìŠ¤ ìš°ì„ )
    filtered_news.sort(key=lambda x: x['importance_score'], reverse=True)
    return filtered_news

def smart_truncate(text, length):
    """ìŠ¤ë§ˆíŠ¸í•˜ê²Œ í…ìŠ¤íŠ¸ ìë¥´ê¸° (ë‹¨ì–´ ë‹¨ìœ„)"""
    if len(text) <= length:
        return text
    
    # ê¸¸ì´ ë‚´ì—ì„œ ë§ˆì§€ë§‰ ê³µë°± ì°¾ê¸°
    truncated = text[:length]
    last_space = truncated.rfind(' ')
    
    if last_space > length * 0.8:  # 80% ì´ìƒì´ë©´ ë‹¨ì–´ ë‹¨ìœ„ë¡œ ìë¥´ê¸°
        return truncated[:last_space] + "..."
    else:
        return truncated + "..."

def collect_filtered_news():
    """ëª¨ë“  ì‚¬ì´íŠ¸ì—ì„œ ë‰´ìŠ¤ ìˆ˜ì§‘ ë° í•„í„°ë§ (ë©€í‹°ì†ŒìŠ¤ ë²„ì „)"""
    all_filtered_news = []
    
    print("ğŸ” ë©€í‹°ì†ŒìŠ¤ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘...")
    print("="*60)
    
    for site_name, feed_url in RSS_FEEDS.items():
        print(f"\nğŸ“° {site_name} ë¶„ì„ ì¤‘...")
        try:
            # RSS í”¼ë“œ íŒŒì‹±
            feed = feedparser.parse(feed_url)
            
            if not hasattr(feed, 'entries') or not feed.entries:
                print(f"   âŒ {site_name}: ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
                continue
            
            print(f"   ğŸ“Š ì „ì²´ ë‰´ìŠ¤: {len(feed.entries)}ê°œ")
            
            # AI í‚¤ì›Œë“œë¡œ í•„í„°ë§
            ai_news = filter_news_by_keywords(feed.entries, AI_KEYWORDS, "AI")
            for news in ai_news:
                news['source'] = site_name
            
            # ì–‘ì í‚¤ì›Œë“œë¡œ í•„í„°ë§  
            quantum_news = filter_news_by_keywords(feed.entries, QUANTUM_KEYWORDS, "Quantum")
            for news in quantum_news:
                news['source'] = site_name
            
            print(f"   ğŸ¤– AI ê´€ë ¨: {len(ai_news)}ê°œ")
            print(f"   âš›ï¸ ì–‘ì ê´€ë ¨: {len(quantum_news)}ê°œ")
            
            # ì–‘ì ì „ë¬¸ ì‚¬ì´íŠ¸ëŠ” íŠ¹ë³„íˆ í‘œì‹œ
            if 'quantum' in site_name.lower() or 'physics' in site_name.lower():
                if quantum_news:
                    print(f"   ğŸ¯ ì–‘ì ì „ë¬¸ ì‚¬ì´íŠ¸ ë§¤ì¹­: {len(quantum_news)}ê°œ")
                    for news in quantum_news[:2]:
                        keywords = news.get('matched_keywords', [])
                        print(f"      âš›ï¸ {news['title'][:40]}... â†’ {keywords[:2]}")
            
            # ë§¤ì¹­ëœ í‚¤ì›Œë“œ ìƒì„¸ ì •ë³´ (ê°„ëµí™”)
            if ai_news and len(ai_news) <= 3:
                for news in ai_news[:1]:
                    keywords = news.get('matched_keywords', [])
                    print(f"   ğŸ¯ AI: {news['title'][:40]}... â†’ {keywords[:2]}")
            
            # ë§¤ì¹­ ì•ˆ ëœ ê²½ìš° (ì–‘ì ì „ë¬¸ ì‚¬ì´íŠ¸ë§Œ)
            if (len(ai_news) == 0 and len(quantum_news) == 0 and 
                ('quantum' in site_name.lower() or 'physics' in site_name.lower())):
                print(f"   âŒ ì–‘ì ì „ë¬¸ ì‚¬ì´íŠ¸ ë§¤ì¹­ ì‹¤íŒ¨. ìµœê·¼ ì œëª©:")
                for i, entry in enumerate(feed.entries[:2], 1):
                    title = entry.title if hasattr(entry, 'title') else "ì œëª© ì—†ìŒ"
                    print(f"      {i}. {title[:50]}...")
            
            all_filtered_news.extend(ai_news)
            all_filtered_news.extend(quantum_news)
            
        except Exception as e:
            print(f"   ğŸ’¥ {site_name} ì˜¤ë¥˜: {e}")
            continue
    
    print("\n" + "="*60)
    print(f"ğŸ¯ ì´ ìˆ˜ì§‘ ê²°ê³¼: {len(all_filtered_news)}ê°œ ë‰´ìŠ¤")
    
    # ì‚¬ì´íŠ¸ë³„ í†µê³„
    site_stats = {}
    ai_stats = {}
    quantum_stats = {}
    
    for news in all_filtered_news:
        source = news.get('source', 'Unknown')
        category = news.get('category', 'Unknown')
        
        site_stats[source] = site_stats.get(source, 0) + 1
        
        if category == 'AI':
            ai_stats[source] = ai_stats.get(source, 0) + 1
        elif category == 'Quantum':
            quantum_stats[source] = quantum_stats.get(source, 0) + 1
    
    print(f"\nğŸ“Š ì‚¬ì´íŠ¸ë³„ ì „ì²´ í†µê³„:")
    for site, count in site_stats.items():
        ai_count = ai_stats.get(site, 0)
        quantum_count = quantum_stats.get(site, 0)
        print(f"   {site}: {count}ê°œ (AI {ai_count}ê°œ, ì–‘ì {quantum_count}ê°œ)")
    
    # ì–‘ì ì „ë¬¸ ì‚¬ì´íŠ¸ ì„±ê³¼
    quantum_sites = [s for s in site_stats.keys() if 'quantum' in s.lower() or 'physics' in s.lower()]
    if quantum_sites:
        print(f"\nâš›ï¸ ì–‘ì ì „ë¬¸ ì‚¬ì´íŠ¸ ì„±ê³¼:")
        for site in quantum_sites:
            q_count = quantum_stats.get(site, 0)
            total = site_stats.get(site, 0)
            print(f"   {site}: ì–‘ì {q_count}ê°œ / ì „ì²´ {total}ê°œ")
    
    return all_filtered_news

def balance_news_by_source_advanced(news_list, max_count, max_per_source=2):
    """ê³ ê¸‰ ì‚¬ì´íŠ¸ë³„ ê· í˜• ë°°ë¶„ - ë¼ìš´ë“œ ë¡œë¹ˆ ë°©ì‹"""
    if not news_list:
        return []
    
    # ì‚¬ì´íŠ¸ë³„ë¡œ ë‰´ìŠ¤ ê·¸ë£¹í•‘
    news_by_source = {}
    for news in news_list:
        source = news['source']
        if source not in news_by_source:
            news_by_source[source] = []
        news_by_source[source].append(news)
    
    # ê° ì‚¬ì´íŠ¸ì˜ ë‰´ìŠ¤ë¥¼ ì¤‘ìš”ë„ìˆœìœ¼ë¡œ ì •ë ¬
    for source in news_by_source:
        news_by_source[source].sort(key=lambda x: x['importance_score'], reverse=True)
    
    balanced = []
    source_count = {source: 0 for source in news_by_source}
    
    # ë¼ìš´ë“œ ë¡œë¹ˆìœ¼ë¡œ ê° ì‚¬ì´íŠ¸ì—ì„œ ìˆœì°¨ì ìœ¼ë¡œ ì„ íƒ
    round_num = 0
    sources = list(news_by_source.keys())
    
    while len(balanced) < max_count and round_num < max_per_source:
        added_this_round = False
        
        for source in sources:
            if len(balanced) >= max_count:
                break
                
            # í•´ë‹¹ ì‚¬ì´íŠ¸ì—ì„œ ì´ë²ˆ ë¼ìš´ë“œì— ì„ íƒí•  ë‰´ìŠ¤ê°€ ìˆëŠ”ì§€ í™•ì¸
            if (round_num < len(news_by_source[source]) and 
                source_count[source] < max_per_source):
                
                news_item = news_by_source[source][round_num]
                balanced.append(news_item)
                source_count[source] += 1
                added_this_round = True
        
        if not added_this_round:
            break
            
        round_num += 1
    
    return balanced

def create_news_summary(news_list, max_news=18):
    """ë‰´ìŠ¤ ìš”ì•½ ë©”ì‹œì§€ ìƒì„± (ê³ ê¸‰ ì‚¬ì´íŠ¸ë³„ ê· í˜• ë²„ì „)"""
    if not news_list:
        return "ğŸ“° ì˜¤ëŠ˜ì€ AI/ì–‘ì ê´€ë ¨ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    # ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë¶„ë¥˜ (ì´ë¯¸ ì¤‘ìš”ë„ìˆœ ì •ë ¬ë¨)
    ai_news = [n for n in news_list if n['category'] == 'AI']
    quantum_news = [n for n in news_list if n['category'] == 'Quantum']
    
    # ê³ ê¸‰ ì‚¬ì´íŠ¸ë³„ ê· í˜• ë§ì¶”ê¸°
    ai_show = balance_news_by_source_advanced(ai_news, max_count=12, max_per_source=2)
    quantum_show = balance_news_by_source_advanced(quantum_news, max_count=6, max_per_source=2)
    
    # ë©”ì‹œì§€ êµ¬ì„±
    current_time = datetime.now().strftime('%Y-%m-%d %H:%M')
    message = f"ğŸ¤– <b>AI & ì–‘ì ë‰´ìŠ¤ ìš”ì•½</b>\n"
    message += f"ğŸ“… {current_time} (í•œêµ­ì‹œê°„)\n"
    message += f"ğŸ¯ ì´ {len(news_list)}ê°œ ë‰´ìŠ¤ ì¤‘ ê· í˜• ì„ ë³„ ë‰´ìŠ¤\n\n"
    
    if ai_show:
        # ì‚¬ì´íŠ¸ë³„ í†µê³„
        ai_sources = {}
        for news in ai_show:
            source = news['source']
            ai_sources[source] = ai_sources.get(source, 0) + 1
        
        source_info = ", ".join([f"{source} {count}ê°œ" for source, count in ai_sources.items()])
        message += f"ğŸ¤– <b>AI ë‰´ìŠ¤ ({len(ai_show)}ê°œ)</b>\n"
        message += f"   ğŸ“Š ì¶œì²˜: {source_info}\n\n"
        
        for i, news in enumerate(ai_show, 1):
            title = smart_truncate(news['title'], 85)
            
            message += f"<b>{i}. {title}</b>\n"
            message += f"   ğŸ“° {news['source']}\n"
            
            # í–¥ìƒëœ ìš”ì•½ ì‚¬ìš©
            enhanced_summary = news.get('enhanced_summary', '')
            if enhanced_summary and len(enhanced_summary) > 5:
                message += f"   ğŸ’¡ {enhanced_summary}\n"
            
            # ë§¤ì¹­ëœ í‚¤ì›Œë“œ í‘œì‹œ (ìµœëŒ€ 3ê°œ)
            if news.get('matched_keywords'):
                keywords = news['matched_keywords'][:3]
                message += f"   ğŸ·ï¸ {', '.join(keywords)}\n"
            
            message += f"   ğŸ”— <a href='{news['link']}'>ê¸°ì‚¬ ë³´ê¸°</a>\n\n"
    
    if quantum_show:
        # ì‚¬ì´íŠ¸ë³„ í†µê³„
        quantum_sources = {}
        for news in quantum_show:
            source = news['source']
            quantum_sources[source] = quantum_sources.get(source, 0) + 1
        
        source_info = ", ".join([f"{source} {count}ê°œ" for source, count in quantum_sources.items()])
        message += f"âš›ï¸ <b>ì–‘ì ë‰´ìŠ¤ ({len(quantum_show)}ê°œ)</b>\n"
        message += f"   ğŸ“Š ì¶œì²˜: {source_info}\n\n"
        
        for i, news in enumerate(quantum_show, 1):
            title = smart_truncate(news['title'], 85)
            
            message += f"<b>{i}. {title}</b>\n"
            message += f"   ğŸ“° {news['source']}\n"
            
            enhanced_summary = news.get('enhanced_summary', '')
            if enhanced_summary and len(enhanced_summary) > 5:
                message += f"   ğŸ’¡ {enhanced_summary}\n"
            
            if news.get('matched_keywords'):
                keywords = news['matched_keywords'][:3]
                message += f"   ğŸ·ï¸ {', '.join(keywords)}\n"
            
            message += f"   ğŸ”— <a href='{news['link']}'>ê¸°ì‚¬ ë³´ê¸°</a>\n\n"
    
    # í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ ê¸¸ì´ ì œí•œ (4096ì)
    if len(message) > 3800:
        message = message[:3800] + "...\n\nğŸ“± <i>ë” ë§ì€ ë‰´ìŠ¤ê°€ ìˆìŠµë‹ˆë‹¤!</i>"
    
    # í†µê³„ ì •ë³´ ì¶”ê°€
    total_ai = len(ai_news)
    total_quantum = len(quantum_news)
    
    # ì „ì²´ ì‚¬ì´íŠ¸ë³„ í†µê³„
    all_sources = {}
    for news in ai_show + quantum_show:
        source = news['source']
        all_sources[source] = all_sources.get(source, 0) + 1
    
    # ì‚¬ì´íŠ¸ ìˆ˜ ê³„ì‚°
    total_sources = len(set([n['source'] for n in news_list]))
    shown_sources = len(all_sources)
    
    message += f"\nğŸ“Š <b>ì˜¤ëŠ˜ì˜ ë‰´ìŠ¤ í†µê³„</b>\n"
    message += f"   ğŸ¤– AI: {total_ai}ê°œ â†’ í‘œì‹œ {len(ai_show)}ê°œ\n"
    message += f"   âš›ï¸ ì–‘ì: {total_quantum}ê°œ â†’ í‘œì‹œ {len(quantum_show)}ê°œ\n"
    message += f"   ğŸ“° í™œì„± ì‚¬ì´íŠ¸: {shown_sources}/{total_sources}ê°œ\n"
    message += f"   ğŸ¯ ê· í˜• ë°°ë¶„: {', '.join([f'{s} {c}ê°œ' for s, c in all_sources.items()])}\n"
    message += f"\nğŸ”„ <i>ë‹¤ìŒ ì—…ë°ì´íŠ¸: 12ì‹œê°„ í›„</i>\n"
    message += f"ğŸ¤– <i>ë©€í‹°ì†ŒìŠ¤ ë‰´ìŠ¤ë´‡ v3.0</i>"
    
    return message

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ ë©€í‹°ì†ŒìŠ¤ ë‰´ìŠ¤ë´‡ v3.0 ì‹œì‘!")
    print(f"â° ì‹¤í–‰ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸŒ ì´ {len(RSS_FEEDS)}ê°œ ì‚¬ì´íŠ¸ ëª¨ë‹ˆí„°ë§ ì¤‘...")
    
    try:
        # 1. ë‰´ìŠ¤ ìˆ˜ì§‘
        news_list = collect_filtered_news()
        print(f"ğŸ“Š ì´ ìˆ˜ì§‘ëœ ë‰´ìŠ¤: {len(news_list)}ê°œ")
        
        # 2. ìš”ì•½ ìƒì„±
        summary = create_news_summary(news_list, max_news=18)
        
        # 3. í…”ë ˆê·¸ë¨ ì „ì†¡
        success = send_telegram_message(summary)
        
        if success:
            print("âœ… ë‰´ìŠ¤ ìš”ì•½ ì „ì†¡ ì™„ë£Œ!")
        else:
            print("âŒ ì „ì†¡ ì‹¤íŒ¨")
            
    except Exception as e:
        error_msg = f"âŒ ë©€í‹°ì†ŒìŠ¤ ë‰´ìŠ¤ë´‡ ì‹¤í–‰ ì˜¤ë¥˜: {e}"
        print(error_msg)
        
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê´€ë¦¬ìì—ê²Œ ì•Œë¦¼
        send_telegram_message(f"ğŸš¨ <b>ë‰´ìŠ¤ë´‡ ì˜¤ë¥˜ ë°œìƒ</b>\n\n{error_msg}")

if __name__ == "__main__":
    main()
