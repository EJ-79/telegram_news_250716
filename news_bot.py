import requests
import feedparser
import json
import re
import time
from datetime import datetime
from config import (
    NEWS_RSS_FEEDS as RSS_FEEDS,
    NEWS_AI_KEYWORDS as AI_KEYWORDS,
    NEWS_QUANTUM_KEYWORDS as QUANTUM_KEYWORDS,
    send_telegram_message
)

def check_keywords_in_text(text, keywords):
    """ê°œì„ ëœ í‚¤ì›Œë“œ ë§¤ì¹­ - ë‹¨ì–´ ê²½ê³„ ê³ ë ¤"""
    if not text:
        return False
    
    text_lower = text.lower()
    
    for keyword in keywords:
        keyword_lower = keyword.lower()
        
        # ë‹¨ì¼ ë‹¨ì–´ì¸ ê²½ìš° ë‹¨ì–´ ê²½ê³„ ì²´í¬
        if ' ' not in keyword_lower:
            # ë‹¨ì–´ ê²½ê³„ì—ì„œë§Œ ë§¤ì¹­ (ì˜ˆ: "AI"ê°€ "said"ì— ë§¤ì¹­ë˜ì§€ ì•Šë„ë¡)
            pattern = r'\b' + re.escape(keyword_lower) + r'\b'
            if re.search(pattern, text_lower):
                return True
        else:
            # êµ¬ë¬¸ì˜ ê²½ìš° ê·¸ëŒ€ë¡œ ì²´í¬
            if keyword_lower in text_lower:
                return True
    
    return False

def filter_news_by_keywords(entries, keywords, category_name):
    """í–¥ìƒëœ í‚¤ì›Œë“œ í•„í„°ë§ - í’ˆì§ˆ ê°œì„ """
    filtered_news = []
    
    for entry in entries:
        title = entry.title if hasattr(entry, 'title') else ""
        summary = entry.summary if hasattr(entry, 'summary') else ""
        full_text = f"{title} {summary}"
        
        # ê°œì„ ëœ í‚¤ì›Œë“œ ë§¤ì¹­
        if not check_keywords_in_text(full_text, keywords):
            continue
            
        # ë§¤ì¹­ëœ í‚¤ì›Œë“œë“¤ ìˆ˜ì§‘
        matched_keywords = []
        full_text_lower = full_text.lower()
        
        for keyword in keywords:
            keyword_lower = keyword.lower()
            
            if ' ' not in keyword_lower:
                # ë‹¨ì–´ ê²½ê³„ ì²´í¬
                pattern = r'\b' + re.escape(keyword_lower) + r'\b'
                if re.search(pattern, full_text_lower):
                    matched_keywords.append(keyword)
            else:
                # êµ¬ë¬¸ ì²´í¬
                if keyword_lower in full_text_lower:
                    matched_keywords.append(keyword)
        
        if matched_keywords:
            # í–¥ìƒëœ ìš”ì•½ ìƒì„±
            enhanced_summary = clean_and_enhance_summary(
                {'title': title, 'summary': summary}, 
                matched_keywords
            )
            
            filtered_news.append({
                'title': title,
                'link': entry.link if hasattr(entry, 'link') else "",
                'published': entry.published if hasattr(entry, 'published') else 'Unknown',
                'summary': summary,
                'enhanced_summary': enhanced_summary,
                'matched_keywords': matched_keywords,
                'category': category_name,
                'source': '',
                'importance_score': len(matched_keywords)
            })
    
    # ì¤‘ìš”ë„ ìˆœìœ¼ë¡œ ì •ë ¬
    filtered_news.sort(key=lambda x: x['importance_score'], reverse=True)
    return filtered_news

def extract_key_sentences(text, keywords):
    """í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë¬¸ì¥ ìš°ì„  ì¶”ì¶œ"""
    if not text:
        return ""
    
    sentences = text.replace('!', '.').replace('?', '.').split('.')
    sentences = [s.strip() for s in sentences if len(s.strip()) > 10]
    
    # í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë¬¸ì¥ ì°¾ê¸°
    keyword_sentences = []
    for sentence in sentences:
        for keyword in keywords:
            if keyword.lower() in sentence.lower():
                keyword_sentences.append(sentence)
                break
    
    # í‚¤ì›Œë“œ ë¬¸ì¥ì´ ìˆìœ¼ë©´ ìš°ì„ , ì—†ìœ¼ë©´ ì²« ë¬¸ì¥
    if keyword_sentences:
        return keyword_sentences[0] + "."
    elif sentences:
        return sentences[0] + "."
    
    return text[:100] + "..." if len(text) > 100 else text

def clean_and_enhance_summary(news_item, relevant_keywords):
    """RSS ìš”ì•½ì„ ì •ë¦¬í•˜ê³  ê°œì„  - ë” ë‚˜ì€ ì²« ë¬¸ì¥ ì¶”ì¶œ"""
    title = news_item.get('title', '')
    summary = news_item.get('summary', '')
    
    # HTML íƒœê·¸ ì œê±°
    summary = re.sub(r'<[^>]+>', '', summary)
    summary = summary.replace('&nbsp;', ' ').replace('&amp;', '&').replace('&quot;', '"')
    
    # ìš”ì•½ì´ ìˆìœ¼ë©´ ìŠ¤ë§ˆíŠ¸í•˜ê²Œ ì²˜ë¦¬
    if summary and len(summary) > 30:
        # ì œëª©ê³¼ ì¤‘ë³µë˜ëŠ” ë‚´ìš© ì œê±°
        title_words = set(title.lower().split())
        
        # ë¬¸ì¥ë“¤ë¡œ ë¶„ë¦¬
        sentences = re.split(r'[.!?]+', summary)
        sentences = [s.strip() for s in sentences if len(s.strip()) > 20]
        
        # ì²« ë²ˆì§¸ë¡œ ì˜ë¯¸ìˆëŠ” ë¬¸ì¥ ì°¾ê¸°
        for sentence in sentences[:3]:  # ì²˜ìŒ 3ë¬¸ì¥ë§Œ í™•ì¸
            sentence_words = set(sentence.lower().split())
            
            # ì œëª©ê³¼ ë„ˆë¬´ ì¤‘ë³µë˜ì§€ ì•Šê³ , í‚¤ì›Œë“œë¥¼ í¬í•¨í•˜ëŠ” ë¬¸ì¥ ì„ í˜¸
            title_overlap = len(title_words & sentence_words) / max(len(title_words), 1)
            has_keyword = any(kw.lower() in sentence.lower() for kw in relevant_keywords)
            
            if title_overlap < 0.7 and (has_keyword or len(sentence) > 40):
                # ë¬¸ì¥ì´ ì™„ì „í•˜ì§€ ì•Šìœ¼ë©´ ë³´ì™„
                if not sentence.endswith(('.', '!', '?')):
                    sentence += '.'
                return sentence
        
        # ì ì ˆí•œ ë¬¸ì¥ì´ ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ ë¬¸ì¥ ì‚¬ìš©
        if sentences:
            first_sentence = sentences[0]
            if not first_sentence.endswith(('.', '!', '?')):
                first_sentence += '.'
            return first_sentence
    
    # ìš”ì•½ì´ ì—†ê±°ë‚˜ ì§§ìœ¼ë©´ í‚¤ì›Œë“œ ê¸°ë°˜ ì„¤ëª…
    return f"{', '.join(relevant_keywords[:2])} ê´€ë ¨ ë‰´ìŠ¤ì…ë‹ˆë‹¤."

def filter_news_by_keywords(entries, keywords, category_name):
    """í‚¤ì›Œë“œë¡œ ë‰´ìŠ¤ í•„í„°ë§ (í–¥ìƒëœ ë²„ì „)"""
    filtered_news = []
    
    for entry in entries:
        title = entry.title if hasattr(entry, 'title') else ""
        summary = entry.summary if hasattr(entry, 'summary') else ""
        full_text = f"{title} {summary}"
        
        # í‚¤ì›Œë“œ ë§¤ì¹­ í™•ì¸
        matched_keywords = []
        for keyword in keywords:
            if keyword.lower() in full_text.lower():
                matched_keywords.append(keyword)
        
        if matched_keywords:
            # í–¥ìƒëœ ìš”ì•½ ìƒì„±
            enhanced_summary = clean_and_enhance_summary(
                {'title': title, 'summary': summary}, 
                matched_keywords
            )
            
            filtered_news.append({
                'title': title,
                'link': entry.link if hasattr(entry, 'link') else "",
                'published': entry.published if hasattr(entry, 'published') else 'Unknown',
                'summary': summary,
                'enhanced_summary': enhanced_summary,  # ìƒˆë¡œìš´ í•„ë“œ
                'matched_keywords': matched_keywords,
                'category': category_name,
                'source': '',
                'importance_score': len(matched_keywords)  # í‚¤ì›Œë“œ ê°œìˆ˜ë¡œ ì¤‘ìš”ë„ ì ìˆ˜
            })
    
    # ì¤‘ìš”ë„ ìˆœìœ¼ë¡œ ì •ë ¬ (í‚¤ì›Œë“œê°€ ë§ì´ ë§¤ì¹­ëœ ë‰´ìŠ¤ ìš°ì„ )
    filtered_news.sort(key=lambda x: x['importance_score'], reverse=True)
    return filtered_news

def smart_truncate(text, length):
    """ìŠ¤ë§ˆíŠ¸í•˜ê²Œ í…ìŠ¤íŠ¸ ìë¥´ê¸° - ë” ê´€ëŒ€í•œ ì„¤ì •"""
    if len(text) <= length:
        return text
    
    # ì œëª©ì€ ì¶©ë¶„íˆ ê¸¸ê²Œ í‘œì‹œ (ê¸°ë³¸ 150ìê¹Œì§€)
    if length < 150:
        length = 150
    
    if len(text) <= length:
        return text
    
    # ê¸¸ì´ ë‚´ì—ì„œ ë§ˆì§€ë§‰ ê³µë°± ì°¾ê¸°
    truncated = text[:length]
    last_space = truncated.rfind(' ')
    
    if last_space > length * 0.8:  # 80% ì´ìƒì´ë©´ ë‹¨ì–´ ë‹¨ìœ„ë¡œ ìë¥´ê¸°
        return truncated[:last_space] + "..."
    else:
        return truncated + "..."

def collect_filtered_news():
    """ëª¨ë“  ì‚¬ì´íŠ¸ì—ì„œ ë‰´ìŠ¤ ìˆ˜ì§‘ ë° í•„í„°ë§ (ë©€í‹°ì†ŒìŠ¤ ë²„ì „)"""
    all_filtered_news = []
    
    print("ğŸ” ë©€í‹°ì†ŒìŠ¤ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘...")
    print("="*60)
    
    for site_name, feed_url in RSS_FEEDS.items():
        print(f"\nğŸ“° {site_name} ë¶„ì„ ì¤‘...")
        try:
            # RSS í”¼ë“œ íŒŒì‹±
            feed = feedparser.parse(feed_url)
            
            if not hasattr(feed, 'entries') or not feed.entries:
                print(f"   âŒ {site_name}: ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
                continue
            
            print(f"   ğŸ“Š ì „ì²´ ë‰´ìŠ¤: {len(feed.entries)}ê°œ")
            
            # AI í‚¤ì›Œë“œë¡œ í•„í„°ë§
            ai_news = filter_news_by_keywords(feed.entries, AI_KEYWORDS, "AI")
            for news in ai_news:
                news['source'] = site_name
            
            # ì–‘ì í‚¤ì›Œë“œë¡œ í•„í„°ë§  
            quantum_news = filter_news_by_keywords(feed.entries, QUANTUM_KEYWORDS, "Quantum")
            for news in quantum_news:
                news['source'] = site_name
            
            print(f"   ğŸ¤– AI ê´€ë ¨: {len(ai_news)}ê°œ")
            print(f"   âš›ï¸ ì–‘ì ê´€ë ¨: {len(quantum_news)}ê°œ")
            
            # ì–‘ì ì „ë¬¸ ì‚¬ì´íŠ¸ëŠ” íŠ¹ë³„íˆ í‘œì‹œ
            if 'quantum' in site_name.lower() or 'physics' in site_name.lower():
                if quantum_news:
                    print(f"   ğŸ¯ ì–‘ì ì „ë¬¸ ì‚¬ì´íŠ¸ ë§¤ì¹­: {len(quantum_news)}ê°œ")
                    for news in quantum_news[:2]:
                        keywords = news.get('matched_keywords', [])
                        print(f"      âš›ï¸ {news['title'][:40]}... â†’ {keywords[:2]}")
            
            # ë§¤ì¹­ëœ í‚¤ì›Œë“œ ìƒì„¸ ì •ë³´ (ê°„ëµí™”)
            if ai_news and len(ai_news) <= 3:
                for news in ai_news[:1]:
                    keywords = news.get('matched_keywords', [])
                    print(f"   ğŸ¯ AI: {news['title'][:40]}... â†’ {keywords[:2]}")
            
            # ë§¤ì¹­ ì•ˆ ëœ ê²½ìš° (ì–‘ì ì „ë¬¸ ì‚¬ì´íŠ¸ë§Œ)
            if (len(ai_news) == 0 and len(quantum_news) == 0 and 
                ('quantum' in site_name.lower() or 'physics' in site_name.lower())):
                print(f"   âŒ ì–‘ì ì „ë¬¸ ì‚¬ì´íŠ¸ ë§¤ì¹­ ì‹¤íŒ¨. ìµœê·¼ ì œëª©:")
                for i, entry in enumerate(feed.entries[:2], 1):
                    title = entry.title if hasattr(entry, 'title') else "ì œëª© ì—†ìŒ"
                    print(f"      {i}. {title[:50]}...")
            
            all_filtered_news.extend(ai_news)
            all_filtered_news.extend(quantum_news)
            
        except Exception as e:
            print(f"   ğŸ’¥ {site_name} ì˜¤ë¥˜: {e}")
            continue
    
    print("\n" + "="*60)
    print(f"ğŸ¯ ì´ ìˆ˜ì§‘ ê²°ê³¼: {len(all_filtered_news)}ê°œ ë‰´ìŠ¤")
    
    # ì‚¬ì´íŠ¸ë³„ í†µê³„
    site_stats = {}
    ai_stats = {}
    quantum_stats = {}
    
    for news in all_filtered_news:
        source = news.get('source', 'Unknown')
        category = news.get('category', 'Unknown')
        
        site_stats[source] = site_stats.get(source, 0) + 1
        
        if category == 'AI':
            ai_stats[source] = ai_stats.get(source, 0) + 1
        elif category == 'Quantum':
            quantum_stats[source] = quantum_stats.get(source, 0) + 1
    
    print(f"\nğŸ“Š ì‚¬ì´íŠ¸ë³„ ì „ì²´ í†µê³„:")
    for site, count in site_stats.items():
        ai_count = ai_stats.get(site, 0)
        quantum_count = quantum_stats.get(site, 0)
        print(f"   {site}: {count}ê°œ (AI {ai_count}ê°œ, ì–‘ì {quantum_count}ê°œ)")
    
    # ì–‘ì ì „ë¬¸ ì‚¬ì´íŠ¸ ì„±ê³¼
    quantum_sites = [s for s in site_stats.keys() if 'quantum' in s.lower() or 'physics' in s.lower()]
    if quantum_sites:
        print(f"\nâš›ï¸ ì–‘ì ì „ë¬¸ ì‚¬ì´íŠ¸ ì„±ê³¼:")
        for site in quantum_sites:
            q_count = quantum_stats.get(site, 0)
            total = site_stats.get(site, 0)
            print(f"   {site}: ì–‘ì {q_count}ê°œ / ì „ì²´ {total}ê°œ")
    
    return all_filtered_news

def balance_news_by_source_advanced(news_list, max_count, max_per_source=2):
    """ê³ ê¸‰ ì‚¬ì´íŠ¸ë³„ ê· í˜• ë°°ë¶„ - ë¼ìš´ë“œ ë¡œë¹ˆ ë°©ì‹"""
    if not news_list:
        return []
    
    # ì‚¬ì´íŠ¸ë³„ë¡œ ë‰´ìŠ¤ ê·¸ë£¹í•‘
    news_by_source = {}
    for news in news_list:
        source = news['source']
        if source not in news_by_source:
            news_by_source[source] = []
        news_by_source[source].append(news)
    
    # ê° ì‚¬ì´íŠ¸ì˜ ë‰´ìŠ¤ë¥¼ ì¤‘ìš”ë„ìˆœìœ¼ë¡œ ì •ë ¬
    for source in news_by_source:
        news_by_source[source].sort(key=lambda x: x['importance_score'], reverse=True)
    
    balanced = []
    source_count = {source: 0 for source in news_by_source}
    
    # ë¼ìš´ë“œ ë¡œë¹ˆìœ¼ë¡œ ê° ì‚¬ì´íŠ¸ì—ì„œ ìˆœì°¨ì ìœ¼ë¡œ ì„ íƒ
    round_num = 0
    sources = list(news_by_source.keys())
    
    while len(balanced) < max_count and round_num < max_per_source:
        added_this_round = False
        
        for source in sources:
            if len(balanced) >= max_count:
                break
                
            # í•´ë‹¹ ì‚¬ì´íŠ¸ì—ì„œ ì´ë²ˆ ë¼ìš´ë“œì— ì„ íƒí•  ë‰´ìŠ¤ê°€ ìˆëŠ”ì§€ í™•ì¸
            if (round_num < len(news_by_source[source]) and 
                source_count[source] < max_per_source):
                
                news_item = news_by_source[source][round_num]
                balanced.append(news_item)
                source_count[source] += 1
                added_this_round = True
        
        if not added_this_round:
            break
            
        round_num += 1
    
    return balanced

def create_ai_news_summary(ai_news):
    """AI ë‰´ìŠ¤ ì „ìš© ë©”ì‹œì§€ ìƒì„±"""
    if not ai_news:
        return None
    
    ai_show = balance_news_by_source_advanced(ai_news, max_count=12, max_per_source=2)
    
    current_time = datetime.now().strftime('%m/%d %H:%M')
    message = f"ğŸ¤– <b>AI ë‰´ìŠ¤ ìš”ì•½</b> ({current_time})\n"
    message += f"ğŸ“Š ì´ {len(ai_news)}ê°œ ì¤‘ {len(ai_show)}ê°œ ì„ ë³„ (ì‚¬ì´íŠ¸ë³„ ê· í˜•)\n\n"
    
    # ì‚¬ì´íŠ¸ë³„ í†µê³„
    ai_sources = {}
    for news in ai_show:
        source = news['source']
        ai_sources[source] = ai_sources.get(source, 0) + 1
    
    source_info = ", ".join([f"{source} {count}ê°œ" for source, count in ai_sources.items()])
    message += f"ğŸ“° ì¶œì²˜: {source_info}\n\n"
    
    for i, news in enumerate(ai_show, 1):
        # ì œëª© ì „ì²´ í‘œì‹œ (ìë¥´ì§€ ì•ŠìŒ)
        title = news['title']
        
        message += f"<b>{i}. {title}</b>\n"
        message += f"   ğŸ“° {news['source']}"
        
        # ë§¤ì¹­ëœ í‚¤ì›Œë“œ í‘œì‹œ
        if news.get('matched_keywords'):
            keywords = news['matched_keywords'][:3]
            message += f" | ğŸ·ï¸ {', '.join(keywords)}"
        
        message += f"\n"
        
        # í–¥ìƒëœ ìš”ì•½(ì²« ë¬¸ì¥) í‘œì‹œ
        enhanced_summary = news.get('enhanced_summary', '')
        if enhanced_summary and len(enhanced_summary) > 10:
            message += f"   ğŸ’¡ {enhanced_summary}\n"
        
        message += f"   ğŸ”— <a href='{news['link']}'>ê¸°ì‚¬ ë³´ê¸°</a>\n\n"
    
    message += f"ğŸ”„ ë‹¤ìŒ ì—…ë°ì´íŠ¸: 12ì‹œê°„ í›„ | ğŸ¤– AIë‰´ìŠ¤ë´‡ v3.2"
    
    return message

def create_quantum_news_summary(quantum_news):
    """ì–‘ì ë‰´ìŠ¤ ì „ìš© ë©”ì‹œì§€ ìƒì„±"""
    if not quantum_news:
        return None
    
    quantum_show = balance_news_by_source_advanced(quantum_news, max_count=6, max_per_source=2)
    
    current_time = datetime.now().strftime('%m/%d %H:%M')
    message = f"âš›ï¸ <b>ì–‘ì ë‰´ìŠ¤ ìš”ì•½</b> ({current_time})\n"
    message += f"ğŸ“Š ì´ {len(quantum_news)}ê°œ ì¤‘ {len(quantum_show)}ê°œ ì„ ë³„ (ì‚¬ì´íŠ¸ë³„ ê· í˜•)\n\n"
    
    # ì‚¬ì´íŠ¸ë³„ í†µê³„
    quantum_sources = {}
    for news in quantum_show:
        source = news['source']
        quantum_sources[source] = quantum_sources.get(source, 0) + 1
    
    source_info = ", ".join([f"{source} {count}ê°œ" for source, count in quantum_sources.items()])
    message += f"ğŸ“° ì¶œì²˜: {source_info}\n\n"
    
    for i, news in enumerate(quantum_show, 1):
        # ì œëª© ì „ì²´ í‘œì‹œ (ìë¥´ì§€ ì•ŠìŒ)
        title = news['title']
        
        message += f"<b>{i}. {title}</b>\n"
        message += f"   ğŸ“° {news['source']}"
        
        # ë§¤ì¹­ëœ í‚¤ì›Œë“œ í‘œì‹œ
        if news.get('matched_keywords'):
            keywords = news['matched_keywords'][:3]
            message += f" | ğŸ·ï¸ {', '.join(keywords)}"
        
        message += f"\n"
        
        # í–¥ìƒëœ ìš”ì•½(ì²« ë¬¸ì¥) í‘œì‹œ
        enhanced_summary = news.get('enhanced_summary', '')
        if enhanced_summary and len(enhanced_summary) > 10:
            message += f"   ğŸ’¡ {enhanced_summary}\n"
        
        message += f"   ğŸ”— <a href='{news['link']}'>ê¸°ì‚¬ ë³´ê¸°</a>\n\n"
    
    message += f"ğŸ”„ ë‹¤ìŒ ì—…ë°ì´íŠ¸: 12ì‹œê°„ í›„ | âš›ï¸ ì–‘ìë‰´ìŠ¤ë´‡ v3.2"
    
    return message

def create_news_summary(news_list, max_news=18):
    """ë‰´ìŠ¤ ìš”ì•½ ë©”ì‹œì§€ ìƒì„± - ë‘ ê°œ ë©”ì‹œì§€ ë°©ì‹"""
    if not news_list:
        return "ğŸ“° ì˜¤ëŠ˜ì€ AI/ì–‘ì ê´€ë ¨ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.", None
    
    # ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë¶„ë¥˜
    ai_news = [n for n in news_list if n['category'] == 'AI']
    quantum_news = [n for n in news_list if n['category'] == 'Quantum']
    
    # ê°ê° ë³„ë„ ë©”ì‹œì§€ ìƒì„±
    ai_message = create_ai_news_summary(ai_news)
    quantum_message = create_quantum_news_summary(quantum_news)
    
    return ai_message, quantum_message

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ - ë‘ ê°œ ë©”ì‹œì§€ ì „ì†¡"""
    print("ğŸš€ ë¶„í•  ë©”ì‹œì§€ ë‰´ìŠ¤ë´‡ v3.2 ì‹œì‘!")
    print(f"â° ì‹¤í–‰ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸŒ ì´ {len(RSS_FEEDS)}ê°œ ì‚¬ì´íŠ¸ ëª¨ë‹ˆí„°ë§")
    print(f"ğŸ“± AI ë‰´ìŠ¤ì™€ ì–‘ì ë‰´ìŠ¤ë¥¼ ë³„ë„ ë©”ì‹œì§€ë¡œ ì „ì†¡")
    
    try:
        # 1. ë‰´ìŠ¤ ìˆ˜ì§‘
        news_list = collect_filtered_news()
        print(f"ğŸ“Š ì´ ìˆ˜ì§‘ëœ ë‰´ìŠ¤: {len(news_list)}ê°œ")
        
        # 2. ì¹´í…Œê³ ë¦¬ë³„ ë¶„ì„
        ai_count = len([n for n in news_list if n['category'] == 'AI'])
        quantum_count = len([n for n in news_list if n['category'] == 'Quantum'])
        print(f"   ğŸ¤– AI ë‰´ìŠ¤: {ai_count}ê°œ")
        print(f"   âš›ï¸ ì–‘ì ë‰´ìŠ¤: {quantum_count}ê°œ")
        
        # 3. ë©”ì‹œì§€ ìƒì„± (ë‘ ê°œ ë³„ë„)
        ai_message, quantum_message = create_news_summary(news_list)
        
        # 4. ë©”ì‹œì§€ ê¸¸ì´ í™•ì¸
        if ai_message:
            print(f"ğŸ“ AI ë©”ì‹œì§€ ê¸¸ì´: {len(ai_message)}ì")
        if quantum_message:
            print(f"ğŸ“ ì–‘ì ë©”ì‹œì§€ ê¸¸ì´: {len(quantum_message)}ì")
        
        # 5. í…”ë ˆê·¸ë¨ ì „ì†¡ (ìˆœì°¨ì )
        success_count = 0
        
        if ai_message:
            print("ğŸ“¤ AI ë‰´ìŠ¤ ë©”ì‹œì§€ ì „ì†¡ ì¤‘...")
            if send_telegram_message(ai_message):
                print("âœ… AI ë‰´ìŠ¤ ì „ì†¡ ì„±ê³µ!")
                success_count += 1
            else:
                print("âŒ AI ë‰´ìŠ¤ ì „ì†¡ ì‹¤íŒ¨")
        
        # ì ê¹ ëŒ€ê¸° (í…”ë ˆê·¸ë¨ API ì œí•œ ê³ ë ¤)
        time.sleep(2)
        
        if quantum_message:
            print("ğŸ“¤ ì–‘ì ë‰´ìŠ¤ ë©”ì‹œì§€ ì „ì†¡ ì¤‘...")
            if send_telegram_message(quantum_message):
                print("âœ… ì–‘ì ë‰´ìŠ¤ ì „ì†¡ ì„±ê³µ!")
                success_count += 1
            else:
                print("âŒ ì–‘ì ë‰´ìŠ¤ ì „ì†¡ ì‹¤íŒ¨")
        
        # 6. ê²°ê³¼ ìš”ì•½
        total_messages = (1 if ai_message else 0) + (1 if quantum_message else 0)
        print(f"ğŸ¯ ì „ì†¡ ê²°ê³¼: {success_count}/{total_messages}ê°œ ë©”ì‹œì§€ ì„±ê³µ")
        
        if success_count == 0:
            print("âŒ ëª¨ë“  ë©”ì‹œì§€ ì „ì†¡ ì‹¤íŒ¨")
        elif success_count == total_messages:
            print("âœ… ëª¨ë“  ë‰´ìŠ¤ ì „ì†¡ ì™„ë£Œ!")
        else:
            print("âš ï¸ ì¼ë¶€ ë©”ì‹œì§€ ì „ì†¡ ì‹¤íŒ¨")
            
    except Exception as e:
        error_msg = f"âŒ ë¶„í•  ë©”ì‹œì§€ ë‰´ìŠ¤ë´‡ v3.2 ì‹¤í–‰ ì˜¤ë¥˜: {e}"
        print(error_msg)
        
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê´€ë¦¬ìì—ê²Œ ì•Œë¦¼
        send_telegram_message(f"ğŸš¨ <b>ë‰´ìŠ¤ë´‡ ì˜¤ë¥˜ ë°œìƒ</b>\n\n{error_msg}")

if __name__ == "__main__":
    main()
